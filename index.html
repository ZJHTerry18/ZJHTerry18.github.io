<!DOCTYPE html>
<html lang="en">
<head>
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-0.872831425-0.8"></script>
	<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());

	gtag('config', 'UA-0.872831425-0.8');
	</script>

	<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

	<meta content="en-us" http-equiv="Content-Language">
	<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
	<title>Jiahe Zhao</title>
	<meta charset="utf-8">
	<style type="text/css">
		.container {
			zoom: 1;
			margin-left: auto;
			margin-right: auto;
			vertical-align: middle;
			text-align: left;
			width: 100%;
			max-width: 800px;
		}
		body {font-family: Arial}
		a {text-decoration:none}
		a:any-link{color: darkred}
     	a:link{color:darkred;}
		a:visited{color:darkred;}
        a:hover{color:darkorange;}

	</style>
</head>

<body style="width:66%;margin:auto" bgcolor="#FFFFFF">
	<table border="0" id="table1" style="margin-left: 8px">
		<tbody>
			<tr>
				<td width="323">
					<p align="center"><font face="Arial"><img border="0" src="figs/hpg_zjh.jpg" height="224"></font></p>
				</td>
				<td >
					<p ><font face="Arial" style="font-size: 26pt;" >&nbsp;Jiahe Zhao<span lang="zh-cn"></span></font></p>

					<p style="margin-top: 3mm;margin-bottom: 0.5mm"><font face="Arial" style="font-size: 12pt;" >&nbsp; Master student at Chinese Academy of Sciences</font></p>
					<p style="margin-top: 3mm;margin-bottom: 0.5mm"><font face="Arial" style="font-size: 12pt;" >&nbsp; Incoming PhD student at MaVi Lab, University of Bristol</font></p>
					<p style="margin-top: 3mm;margin-bottom: 0.5mm"><font face="Arial" style="font-size: 12pt;">&nbsp; <b>Email</b>: zhaojiahe1 at gmail dot com</font></p>
					&nbsp;
					<a href="https://scholar.google.com/citations?user=dG_NwQYAAAAJ&hl=zh-CN" style="font-size: 12pt;"><b>Google Scholar</b></a> &bull;
					<a href="https://github.com/ZJHTerry18" style="font-size: 12pt;"><b>GitHub</b></a>
				</td>

			</tr>
		</tbody>
	</table>

<table style="margin-left: 55px;margin-right: 55px">
		<tbody>
			<td>
				<td style="border-style: none; border-width: medium;">
					<p style="margin-top: 3px; margin-bottom: 3px;"><font face="Arial" style="font-size: 12pt;">
						I am a final year Master student at VIPL Lab, Institute of Computing Technology, Chinese Academy of Sciences, supervised by Prof. <a href="https://vipl.ict.ac.cn/people/hchang/">Hong Chang</a>.
						I achieved my bachelor's degree from the Department of Automation, Tsinghua University.
						I'm an incoming PhD student at <a href="https://uob-mavi.github.io/people/">Mavi Lab</a>, University of Bristol, supervised by Prof. <a href="https://dimadamen.github.io/">Dima Damen</a>.
						I have spent wonderful times as a visiting student at the University of Hong Kong and Shanghai AI Laboratory, supervised by Prof. <a href="https://i.cs.hku.hk/~hszhao/">Hengshuang Zhao</a> and Dr. <a href="https://shepnerd.github.io/">Yi Wang</a>.
						<br>
						<br>
						My research interests lie in <b style="color: darkblue">multi-modal learning</b>, <b style="color: darkblue">human-centric learning</b> and <b style="color: darkblue">video understanding</b>. Now I am particularly focused on <b style="color: darkblue">egocentric video understanding</b>. Feel free to drop me an email if you want to communicate.
						<br>
						<br>
					</font></p>
				</td>
			</td>
		</tbody>
</table>

<table style="width:80%;margin-left: 55px;border-spacing: 0;">
	<tbody>
	<tr>
		<p style="margin-left: 60px;margin-bottom: 10px"><b><font face="Arial" size="5">
		Selected Publications </font></b></p>
	</tr>

	<tr align="left">
		<td width="30%" style="vertical-align: middle;"><p><img src="./figs/DisCo_ICCV25.jpg" height="140" width="240" alt="DisCo"></p></td>
		<td width="70%" style="vertical-align: middle;"><p style="font-size: 12pt;line-height: 1.2;width: 16cm; margin-left: 10px;">
			<strong >DisCo: Towards Distinct and Coherent Visual Encapsulation in Video MLLMs</strong><br>
					<span style="text-decoration: underline">Jiahe Zhao</span>, Rongkun Zheng, Yi Wang, Helin Wang, Hengshuang Zhao<br>
					<em>International Conference on Computer Vision (<b>ICCV</b>), 2025. <br> 		
					<b><a href="https://arxiv.org/abs/2507.10302">Paper</a></b> |
					<b><a href="https://github.com/ZJHTerry18/DisCo">Code</a></b>
			</p></td></tr>

	<tr align="left">
		<td width="30%" style="vertical-align: middle;"><p><img src="./figs/HISGPT_ICCV25.jpg" height="140" width="240" alt="HIS-GPT"></p></td>
		<td width="70%" style="vertical-align: middle;"><p style="font-size: 12pt;line-height: 1.2;width: 16cm; margin-left: 10px;">
			<strong >HIS-GPT: Towards 3D Human-In-Scene Multimodal Understanding</strong><br>
					<span style="text-decoration: underline">Jiahe Zhao</span>, Ruibing Hou, Zejie Tian, Hong Chang, Shiguang Shan<br>
					<em>International Conference on Computer Vision (<b>ICCV</b>), 2025. <br> 		
					<b><a href="https://ieeexplore.ieee.org/document/10908873">Paper</a></b> |
					<b><a href="https://github.com/ZJHTerry18/HumanInScene">Code</a></b>
			</p></td></tr>
		
	<tr align="left">
		<td width="30%" style="vertical-align: middle;"><p><img src="./figs/FAIM_TMM25.jpg" height="140" width="240" alt="FAIM"></p></td>
		<td width="70%" style="vertical-align: middle;"><p style="font-size: 12pt;line-height: 1.2;width: 16cm; margin-left: 10px;">
			<strong >Clothes-Changing Person Re-Identification with Feasibility-Aware Intermediary Matching</strong><br>
					<span style="text-decoration: underline">Jiahe Zhao</span>, Ruibing Hou, Hong Chang, Xinqian Gu, Bingpeng Ma, Shiguang Shan, Xilin Chen<br>
					<em>IEEE Transactions on Multimedia (<b>TMM</b>), 2025. <br> 		
					<b><a href="https://ieeexplore.ieee.org/document/10908873">Paper</a></b> |
					<b><a href="https://github.com/ZJHTerry18/FAIM">Code</a></b>
			</p></td></tr>

	<tr align="left">
		<td width="30%" style="vertical-align: middle;"><p><img src="./figs/HERM_arxiv24.jpg" height="140" width="240" alt="HERM"></p></td>
		<td width="70%" style="vertical-align: middle;"><p style="font-size: 12pt;line-height: 1.2;width: 16cm; margin-left: 10px;">
			<strong >HERM: Benchmarking and Enhancing Multimodal LLMs for Human-Centric Understanding</strong><br>
					Keliang Li*, Zaifei Yang*, <span style="text-decoration: underline">Jiahe Zhao*</span>, Hongze Shen, Ruibing Hou, Hong Chang, Shiguang Shan, Xilin Chen<br>
					<em>arxiv, 2024. <br> 		
					<b><a href="https://arxiv.org/abs/2410.06777">Paper</a></b> |
					<b><a href="https://github.com/ZJHTerry18/Human-Centric-MLLM">Code</a></b>
			</p></td></tr>
	</tbody>
</table>

<br>
<br>
	
<p style="margin-left: 60px;margin-top: -30px"><b><font size="5"><br>
	Work Experiences and Internships</font></b></p>
	<font style="font-size: 12pt; line-height: 1.25;">
		<ul style="margin-left: 60px;margin-top: -10px">
			<li><b><a href="https://i.cs.hku.hk/~hszhao/lab.html">CSAIL</a>, HKU</b>: Summer research intern for computer vision, supervised by Prof. <a href="https://i.cs.hku.hk/~hszhao/">Henshuang Zhao</a>, 2024</li>
			<li><b><a href="https://www.shlab.org.cn/">Shanghai AI Laboratory</a></b>: Video multi-modal large language models (MLLMs), where I worked with Dr. <a href="https://shepnerd.github.io/">Yi Wang</a>, 2024</li>
			<li><b>Megvii</b>: Object detection for intelligent industrial and traffic devices, 2023</li>
		</ul>
	</font>
<br>
<br>

</body>
</html>
